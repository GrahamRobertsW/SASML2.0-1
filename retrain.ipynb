{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b4fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import VirtualInstrument\n",
    "import ParamGenerator as SG\n",
    "import json\n",
    "import TreeHierarchy as TH\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "import ArrayTuner\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7459e1d",
   "metadata": {},
   "source": [
    "# Random sampling function\n",
    "For every morphology in the dataset we need a function that can generate a set of random examples, random draws of the structural parameters.  This portion of the code certainly contains a level of techinical debt and is ripe for improvement when genrealizing the model to new tasks. Each morphology is assigned one function that merely takes the number of desired samples as an argument. All the mins and maxes as well as the sampling type (uniform vs logarithmic are the most common choices) are baked into these functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2c1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_params = ['radius', 'length', 'thick_sell', 'thick_solvent', 'background', 'scale', 'n_shells', 'sld' ,'sld_core', 'sld_solvent', 'sld_shell', 'radius_pd_n', 'length_pd_n', 'radius_pd_nsigma', 'length_pd_nsigma', 'kuhn_length', 'radius_pd', 'length_pd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9d0ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['q', 'I', 'dI', 'dq'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grahamroberts/qyangwork/exsas/SASML2.0/src/VirtualInstrument.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(fn, delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "reference_files = [\"data/bg_sub/S_r30405_0p1_Bicelles_100mM_NaCl.csv\"]\n",
    "vi = VirtualInstrument.VirtualInstrument()\n",
    "vi.add_references(reference_files)\n",
    "refdf = pd.DataFrame(pd.read_csv(reference_files[0], sep='\\s+'))\n",
    "erf = np.array(refdf.loc[:,'dI'])\n",
    "q = np.array(refdf.loc[:,'q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65204808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_MLS(count):\n",
    "    n_shells = np.random.randint(3, 40, count)\n",
    "    radii = np.random.uniform(10, 2500, count)\n",
    "    shell_thick = np.random.uniform(15,120,count)\n",
    "    water_thick = np.random.uniform(2,50,count)\n",
    "    scales = np.random.uniform(0.005, 0.05, count)\n",
    "    sld= np.random.uniform(1., 2., count)\n",
    "    radius_pds = np.random.uniform(0.1, 0.5, count)\n",
    "    #background = np.random.uniform(-3.5,-1,count)\n",
    "    #sld_solvent = np.random.uniform(4.4,8.4,count)\n",
    "    #scale = np.random.uniform(0.1, 1.0, count)\n",
    "    return_list = [{\"n_shells\": n_shells[i],\n",
    "                    \"radius\": radii[i],\n",
    "                    \"thick_shell\": shell_thick[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"sld\": sld[i],\n",
    "                    \"radius_pd\": radius_pds[i],\n",
    "                    \"radius_pd_type\":\"schulz\",\n",
    "                    \"radius_pd_n\": 8,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"thick_solvent\": water_thick[i]} for i in range(count)]\n",
    "        #            \"background\": 10**background[i],\n",
    "        #            \"sld_solvent\": sld_solvent[i],\n",
    "        #            \"sld\": sld[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea93261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cylinder(count):\n",
    "    radii = np.random.uniform(10, 2500, count)\n",
    "    length = np.random.uniform(25, 500, count)\n",
    "    sld = np.random.uniform(.5, 3.0, count)\n",
    "    radius_pds = np.random.uniform(0.1, 0.5, count)\n",
    "    #background = np.random.uniform(-3.5,-1,count)\n",
    "    scales = np.random.uniform(0.0005, 0.05, count)\n",
    "\n",
    "    #sld_solvent = np.random.uniform(4.4,8.4,count)\n",
    "    #scale = np.random.uniform(0.1, 1.0, count)\n",
    "    return_list = [{\"radius\":radii[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"sld\": sld[i],\n",
    "                    \"radius_pd\": radius_pds[i],\n",
    "                    \"radius_pd_type\":\"schulz\",\n",
    "                    \"radius_pd_n\": 8,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"length\":2*radii[i]+length[i]} for i in range(count)]\n",
    "           #         \"background\": 10**background[i],\n",
    "           #         \"sld_solvent\": sld_solvent[i],\n",
    "           #         \"scale\": scale[i],\n",
    "           #         \"sld\":sld[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6a2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_disk(count):\n",
    "    radii = np.random.uniform(20.0, 400.0, count)\n",
    "    length = np.random.uniform(40.0, 30.0, count)\n",
    "    scales = np.random.uniform(0.0001, 0.005, count)\n",
    "    length_pds = np.random.uniform(0.1, 0.5, count)\n",
    "    #background = np.random.uniform(-3.5,-1,count)\n",
    "    #sld_solvent = np.random.uniform(4.4,8.4,count)\n",
    "    #scale = np.random.uniform(0.1, 1.0, count)\n",
    "    sld = np.random.uniform(1., 2.0, count)\n",
    "    return_list = [{\"radius\":length[i]+radii[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"sld\": sld[i],\n",
    "                    \"radius_pd\": length_pds[i],\n",
    "                    \"radius_pd_type\":\"schulz\",\n",
    "                    \"radius_pd_n\": 8,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"length\":length[i]} for i in range(count)]\n",
    "     #               \"background\": 10**background[i],\n",
    "     #               \"sld_solvent\": sld_solvent[i],\n",
    "     #               \"scale\": scale[i],\n",
    "     #               \"sld\":sld[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385a059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vesicle(count):\n",
    "    thickness = np.random.uniform(15, 120, count)\n",
    "    radii = np.random.uniform(25, 2000, count)\n",
    "    scales = np.random.uniform(0.0005, 0.05, count)\n",
    "    sld = np.random.uniform(1., 2., count)\n",
    "    radius_pds = np.random.uniform(3.5, 0.5, count)\n",
    "    return_list = [{\"radius\": radii[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"sld\": sld[i],\n",
    "                    \"radius_pd\": radius_pds[i],\n",
    "                    \"radius_pd_type\":\"schulz\",\n",
    "                    \"radius_pd_n\": 8,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"thickness\": thickness[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f156852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cs_disk(count):\n",
    "    radii = np.random.uniform(100.0, 1000.0, count)\n",
    "    length = np.random.uniform(40.0, 60.0, count)\n",
    "    shell_thick = np.random.uniform(30,60,count)\n",
    "    scales = np.random.uniform(0.0005, 0.15, count)\n",
    "    length_pds = np.random.uniform(0.1, 0.3, count)\n",
    "    #background = np.random.uniform(-3.5,-1,count)\n",
    "    #sld_solvent = np.random.uniform(4.4,8.4,count)\n",
    "    #scale = np.random.uniform(0.1, 1.0, count)\n",
    "    #sld = np.random.uniform(0.5, 5.0, count)\n",
    "    #sld_shell = np.random.uniform(0.,4.,count)\n",
    "    return_list = [{\"radius\":length[i]+radii[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"length_pd\": length_pds[i],\n",
    "                    \"length_pd_type\":\"schulz\",\n",
    "                    \"length_pd_n\": 8,\n",
    "                    \"length_pd_nsigma\": 30,\n",
    "                    \"length\":length[i]} for i in range(count)]\n",
    "                    #\"background\": 10**background[i],\n",
    "                    #\"sld_solvent\": sld_solvent[i],\n",
    "                    #\"sld_shell\": sld_shell[i],\n",
    "                    #\"scale\": scale[i],\n",
    "                    #\"sld_core\":sld[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8513a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cs_sphere(count):\n",
    "    radii = np.random.uniform(50, 1000, count)\n",
    "    shell_thick = np.random.uniform(25,100,count)\n",
    "    background = np.random.uniform(-3.5,-1,count)\n",
    "    scales = np.random.uniform(0.0005, 0.05, count)\n",
    "    radius_pds = np.random.uniform(0.1, 0.2, count)\n",
    "    #sld_solvent = np.random.uniform(4.4,8.4,count)\n",
    "    #scale = np.random.uniform(0.1, 1.0, count)\n",
    "    sld= np.random.uniform(1., 2.0, count)\n",
    "    sld_shell = np.random.uniform(0.,4.,count)\n",
    "    return_list = [{\"radius\": radii[i],\n",
    "                    \"thickness\": shell_thick[i],\n",
    "                    \"background\": 10**background[i],\n",
    "                    \"sld_solvent\": sld_solvent[i],\n",
    "                    \"sld_shell\": sld_shell[i],\n",
    "                    \"scale\": scales[i],\n",
    "                    \"radius_pd\": radius_pds[i],\n",
    "                    \"radius_pd_type\":\"schulz\",\n",
    "                    \"radius_pd_n\": 8,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"sld_core\": sld[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_wormlike_micelle(count):\n",
    "    length = np.random.uniform(200, 1000, count)\n",
    "    radii = np.random.uniform(10, 100, count)\n",
    "    scales = np.random.uniform(0.0001, 0.005, count)\n",
    "    #background = np.random.uniform(-3.5, -1, count)\n",
    "    #background = np.random.uniform(0.001, 0.001, count)\n",
    "    kuhn_length = np.random.uniform(400, 600, count)\n",
    "    pds = np.random.uniform(0.3, 0.5, count)\n",
    "    axis_ratio = np.random.uniform(2., 10.0, count)\n",
    "    sld = np.random.uniform(1., 2., count)\n",
    "    return_list = [{\"radius\":radii[i],\n",
    "                    \"length\":length[i],\n",
    "                    #\"background\":10**background[i],\n",
    "                    \"kuhn_length\":kuhn_length[i],\n",
    "                    \"radius_pd\": pds[i],\n",
    "                    \"radius_pd_type\": \"schulz\",\n",
    "                    \"scale\": scales[i],\n",
    "                    \"sld\": sld[i],\n",
    "                    \"radius_pd_n\": 8.,\n",
    "                    \"radius_pd_nsigma\": 30,\n",
    "                    \"axis_ratio\":axis_ratio[i]} for i in range(count)]\n",
    "    return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c33eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_params(d1, d2):\n",
    "    outlist = list(d1.keys())\n",
    "    for k in d2.keys():\n",
    "        if k not in outlist:\n",
    "            outlist += [k]\n",
    "    return(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aae3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pdict(indict, default_dict):\n",
    "    #params_to_map = [\"n_shells\", \"radius\", \"thick_shell\", \"thick_solvent\", \"sld\"]\n",
    "    #params_to_map = union_params(indict, default_dict)\n",
    "    params_to_map = indict.keys()\n",
    "    defaults = {key: default_dict[key] for key in default_dict.keys() if key not in indict.keys()}\n",
    "    outdict = {key:indict[key] for key in params_to_map} | defaults\n",
    "    return(outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc7af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_noise(curves, reference, noise_scale = 0.00):\n",
    "    newcurves = curves.copy()\n",
    "    for i in range(curves.shape[0]):\n",
    "        noise = np.random.normal(reference.shape)*reference*noise_scale* np.random.choice([-1,1], newcurves[i].shape)\n",
    "        newcurves[i] += noise\n",
    "    return(newcurves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf4c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61889d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_SAS_curves(count):\n",
    "    all_curves = []\n",
    "    all_labels =[]\n",
    "    all_params = {}\n",
    "    for t in targets.keys():\n",
    "        print(t)\n",
    "        t_list, n_list = None, None\n",
    "        model_name = model_names[t] if t in model_names.keys() else t\n",
    "        calcs, sds = vi.construct_calculators(model_name)\n",
    "        t_list, n_list = generators[t].sample(count)\n",
    "        all_params[t] = unwrap_params(n_list)\n",
    "        param_df = tabularize_params(n_list)\n",
    "        param_df.to_csv(\"parameters_%s.csv\"%(t))\n",
    "        curves = [vi.generate(model_name, kw, calcs, sds)[0] for kw in n_list]\n",
    "        all_curves += curves\n",
    "        all_labels += [t for i in range(count)]\n",
    "    param_lists = concat_params(all_labels, all_params)\n",
    "    q = all_curves[0].index\n",
    "    all_curves = np.array(all_curves)\n",
    "    all_valid = filter_nan(all_curves)\n",
    "    all_curves = all_curves[all_valid]\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_labels = all_labels[all_valid]\n",
    "    for p in param_lists.keys():\n",
    "         param_lists[p] = param_lists[p][all_valid]\n",
    "    return(all_curves, all_labels, param_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f8df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some dictionaries of the various defaults for parameters we aren't randomly sampling.\n",
    "\n",
    "general_default_dict = {\"scale\":.01,\n",
    "                 \"background\": 0.003,\n",
    "                 \"sld_solvent\": 6.4,\n",
    "                 \"radius_pd\":.3,\n",
    "                 \"radius_pd_n\":40,\n",
    "                 \"radius_pd_type\":\"schulz\"}\n",
    "cylinder_default_dict = {\"scale\":.01,\n",
    "                 \"background\": 0.003,\n",
    "                 \"sld_solvent\": 6.4,\n",
    "                 \"length_pd\":.3,\n",
    "                 \"length_pd_n\":40,\n",
    "                 \"length_pd_type\":\"schulz\"}\n",
    "cs_sphere_default_dict = {\"scale\":.01,\n",
    "                 \"background\": 0.003,\n",
    "                 \"sld_solvent\": 6.4,\n",
    "                 #\"sld_core\": 6.4,\n",
    "                 \"radius_pd\":.3,\n",
    "                 \"radius_pd_n\":40,\n",
    "                 \"radius_pd_type\":\"schulz\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa66882",
   "metadata": {},
   "source": [
    "Below are a few helper functions to format the data into an xarray as well as filter out any NaN etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc4d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nan(arr):\n",
    "    return(np.where(np.all(np.logical_not(np.isnan(arr)), axis=1))[0])\n",
    "\n",
    "\n",
    "\n",
    "def tabularize_params(param_table):\n",
    "    keys = param_table[0].keys()\n",
    "    lim = len(param_table)\n",
    "    outdf = {k:np.array([p[k] for p in param_table]) for k in keys}\n",
    "    return(pd.DataFrame(outdf))\n",
    "\n",
    "def make_map_function(reference_dict):\n",
    "    def newfunc(indict):\n",
    "        return(map_pdict(indict, reference_dict))\n",
    "    return(newfunc)\n",
    "\n",
    "def concat_params(labels, params):\n",
    "    unique_params = []\n",
    "    ptypes = {}\n",
    "    for morphology in params.keys():\n",
    "        for param in params[morphology].keys():\n",
    "            if param not in unique_params:\n",
    "                unique_params += [param]\n",
    "                pt = type(params[morphology][param][0])\n",
    "                if pt in [float, int, np.float64, np.int64]:\n",
    "                    t = pt\n",
    "                else:\n",
    "                    t = object\n",
    "                ptypes[param] = t\n",
    "    all_params = {param: np.zeros(len(labels), dtype = ptypes[param]) for param in unique_params}\n",
    "    for morphology in params.keys():\n",
    "        #inds = np.where(labels == morphology)[0]\n",
    "        inds = np.where(np.array([lab == morphology for lab in labels]))[0]\n",
    "        for param in unique_params:\n",
    "            if param in params[morphology].keys():\n",
    "                all_params[param][inds] = params[morphology][param]\n",
    "            else:\n",
    "                if param in numeric_params:\n",
    "                    all_params[param][inds] = np.nan * np.ones(inds.shape[0])\n",
    "                else:\n",
    "                    all_params[param][inds] = None\n",
    "    return(all_params)\n",
    "\n",
    "def unwrap_params(params):\n",
    "    unique_params = params[0].keys()\n",
    "    params = {p: np.array([para[p] for para in params]) for p in unique_params}\n",
    "    return(params)\n",
    "\n",
    "def bg_norm(curves, bg = 0.01, noise_scale = 0.00, minval = 0.001):\n",
    "    new_curves = np.zeros(curves.shape)\n",
    "    incoherence = bg*np.ones(curves.shape)\n",
    "    random_noise = np.random.normal(size = curves.shape)*noise_scale*np.random.choice([-1,1],curves.shape)\n",
    "    new_curves += incoherence+random_noise\n",
    "    for i in range(curves.shape[0]):\n",
    "        new_curves[i,:] = curves[i,:] - np.min(curves[i,:]) + minval\n",
    "    return(new_curves)\n",
    "\n",
    "def make_xarray(curves, params, labels, q, test_curves = None, test_params = None, test_labels = None):\n",
    "    new_array = xr.Dataset()\n",
    "    inds = np.arange(labels.shape[0])\n",
    "    test_inds = np.arange(test_labels.shape[0])\n",
    "    new_array['sample'] = inds\n",
    "    new_array['q'] = q\n",
    "    new_array['SAS_curves'] = (['sample', 'q'], curves)\n",
    "    new_array['labels'] = (['sample'], labels)\n",
    "    for p in params.keys():\n",
    "        new_array[p] = (['sample'], params[p])\n",
    "    if test_curves is not None and test_params is not None and test_labels is not None:\n",
    "        new_array['test_sample'] = test_inds\n",
    "        new_array['test_curves'] = (['test_sample', 'q'], test_curves)\n",
    "        new_array['test_labels'] = (['test_sample'], test_labels)\n",
    "        for p in test_params.keys():\n",
    "            new_array[\"test_%s\"%(p)] = (['test_sample'], params[p])\n",
    "    return(new_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040e287",
   "metadata": {},
   "source": [
    "## Defining constants of the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e75ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "   count = 1000\n",
    "   targets = {'flexible_cylinder_elliptical': random_wormlike_micelle,\n",
    "              'core_shell_sphere': random_vesicle,\n",
    "              'multilayer_vesicle': random_MLS,\n",
    "              'disk': random_disk}\n",
    "             #'core_shell_disk': random_cs_disk}\n",
    "   default_map = {'flexible_cylinder_elliptical': general_default_dict,\n",
    "              'core_shell_sphere': cs_sphere_default_dict,\n",
    "              'multilayer_vesicle': general_default_dict,\n",
    "              'disk': cylinder_default_dict}\n",
    "             # 'core_shell_disk': cs_sphere_default_dict}\n",
    "\n",
    "   model_names = {'disk':'cylinder', \"core_shell_disk\": \"core_shell_cylinder\", \"core_shell_sphere\": \"vesicle\"}\n",
    "   parameterizers = {t: make_map_function( default_map[t]) for t in targets.keys()}\n",
    "\n",
    "   generators = {t:SG.ParamGenerator(targets[t], parameterizers[t]) for t in targets.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e8402",
   "metadata": {},
   "source": [
    "# Simulating Data\n",
    "##configure virtual instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7dcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1f3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da913d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flexible_cylinder_elliptical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1020646/2009739867.py\", line 1, in <module>\n",
      "    source_train_curves, train_labels, train_params = sample_SAS_curves(count)\n",
      "  File \"/tmp/ipykernel_1020646/3231890156.py\", line 9, in sample_SAS_curves\n",
      "    calcs, sds = vi.construct_calculators(model_name)\n",
      "  File \"/home/grahamroberts/qyangwork/exsas/SASML2.0/src/VirtualInstrument.py\", line 86, in construct_calculators\n",
      "    model= sasmodels.core.load_model(model_name)\n",
      "  File \"/home/grahamroberts/.local/lib/python3.10/site-packages/sasmodels/core.py\", line 127, in load_model\n",
      "    return build_model(load_model_info(model_name),\n",
      "  File \"/home/grahamroberts/.local/lib/python3.10/site-packages/sasmodels/core.py\", line 329, in build_model\n",
      "    numpy_dtype, fast, platform = parse_dtype(model_info, dtype, platform)\n",
      "  File \"/home/grahamroberts/.local/lib/python3.10/site-packages/sasmodels/core.py\", line 414, in parse_dtype\n",
      "    from . import kernelcl\n",
      "  File \"/home/grahamroberts/.local/lib/python3.10/site-packages/sasmodels/kernelcl.py\", line 73, in <module>\n",
      "    import pyopencl as cl  # type: ignore\n",
      "  File \"/usr/lib/python3/dist-packages/pyopencl/__init__.py\", line 28, in <module>\n",
      "    import pyopencl.cltypes  # noqa: F401\n",
      "  File \"/usr/lib/python3/dist-packages/pyopencl/cltypes.py\", line 22, in <module>\n",
      "    from pyopencl.tools import get_or_register_dtype\n",
      "  File \"/usr/lib/python3/dist-packages/pyopencl/tools.py\", line 36, in <module>\n",
      "    from pyopencl._cl import bitlog2  # noqa: F401\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_shell_sphere\n",
      "multilayer_vesicle\n",
      "disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1020646/2215531907.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  all_params[param][inds] = np.nan * np.ones(inds.shape[0])\n"
     ]
    }
   ],
   "source": [
    "source_train_curves, train_labels, train_params = sample_SAS_curves(count)\n",
    "#train_curves = random_noise(source_train_curves, erf)\n",
    "train_curves = source_train_curves\n",
    "train_curves = bg_norm(train_curves)\n",
    "log_train = np.log10(train_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d050c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flexible_cylinder_elliptical\n",
      "core_shell_sphere\n",
      "multilayer_vesicle\n",
      "disk\n"
     ]
    }
   ],
   "source": [
    "source_test_curves, test_labels, test_params = sample_SAS_curves(count)\n",
    "#test_curves = random_noise(source_test_curves, erf)\n",
    "test_curves = source_test_curves\n",
    "test_curves = bg_norm(test_curves)\n",
    "log_test = np.log10(test_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250b249",
   "metadata": {},
   "source": [
    "#Tuning the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_range(val, bounds):\n",
    "    return(val * (bounds[1]-bounds[0]) + bounds[0])\n",
    "\n",
    "def scale_binary(val, bounds):\n",
    "    return(bounds[0] if val < 0.5 else bounds[1])\n",
    "\n",
    "def ident(x):\n",
    "    return(x)\n",
    "\n",
    "param_list = [\"C\", \"gamma\", \"coef0\"]\n",
    "pbounds = {\"C\": (-5,5),\n",
    "           \"gamma\": (\"auto\", \"scale\"),\n",
    "           \"coef0\": (0,1)}\n",
    "select_map = {\"C\": scale_range,\n",
    "              \"gamma\": scale_binary,\n",
    "              \"coef0\": scale_binary}\n",
    "wrapper_map = {\"C\": lambda x: 10**x,\n",
    "               \"gamma\": ident,\n",
    "               \"coef0\": ident}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rbf_SVC_sample(arr):\n",
    "    return({param_list[i]: wrapper_map[param_list[i]](select_map[param_list[i]](arr[i], pbounds[param_list[i]])) for (i,p) in enumerate(arr)} | {\"type\": \"SVC\", \"kernel\": {\"type\": \"rbf\"}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LHS_params(params, map_func, count=20):\n",
    "    num_params = len(params)\n",
    "    lh = LatinHypercube(num_params)\n",
    "    outarr = [map_func(v) for v in lh.random(count)]\n",
    "    return(outarr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(args):\n",
    "    X = np.log10(np.loadtxt(args.X, delimiter=','))\n",
    "    y = np.loadtxt(args.y, delimiter=',', dtype = str)\n",
    "    test_X = np.log10(np.loadtxt(args.test_X, delimiter=','))\n",
    "    test_y = np.loadtxt(args.test_y, delimiter=',', dtype = str)\n",
    "    return(X, y, test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bf272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(X, y, C1, C2):\n",
    "    relevant_inds = np.where(np.logical_or(np.isin(y, C1), np.isin(y, C2)))[0]\n",
    "    temp_X = X[relevant_inds]\n",
    "    #temp_y = y[relevan_inds]\n",
    "    temp_y = np.zeros(temp_X.shape[0])\n",
    "    temp_y[np.where(np.isin(y[relevant_inds], C2))[0]] = 1\n",
    "    return(temp_X, temp_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(fn):\n",
    "    infile = open(fn, \"r\")\n",
    "    indat = infile.read()\n",
    "    j_string = json.loads(indat)\n",
    "    return(j_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(fn):\n",
    "    jdict = parse_json(fn)\n",
    "    tree = TH.TreeHierarchy()\n",
    "    #tree.from_json(jdict)\n",
    "    tree.structure_from_json(jdict)\n",
    "    return(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_KFold(X, y, classifier, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits = n_splits, shuffle=True)\n",
    "    sum_perf = 0\n",
    "    for val_inds, train_inds in skf.split(X,y):\n",
    "        classifier.fit(X[train_inds], y[train_inds])\n",
    "        sum_perf += accuracy_score(y[val_inds], classifier.predict(X[val_inds]))\n",
    "    return(sum_perf / n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c311a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svc(p):\n",
    "    svc = SVC(C = p[\"C\"],\n",
    "              gamma = p[\"gamma\"],\n",
    "              coef0 = p[\"coef0\"],\n",
    "              kernel = p[\"kernel\"][\"type\"],\n",
    "              degree = p[\"kernel\"][\"degree\"] if p[\"kernel\"][\"type\"] == \"poly\" else 0)\n",
    "    return(svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781889e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune_tree(tree, X, y):\n",
    "    if not getattr(tree, 'terminal', False):\n",
    "       tX, ty = select_data(X, y, tree.classA, tree.classB)\n",
    "       params = LHS_params(param_list, map_rbf_SVC_sample, count=50)\n",
    "       tuner = ArrayTuner.ArrayTuner(params)\n",
    "       for p in tuner:\n",
    "           tuner.report([p], inverse_KFold(tX, ty, create_svc(p)))\n",
    "       setattr(tree, \"entity\", create_svc(tuner.best[0]))\n",
    "       tune_tree(tree.left, X, y)\n",
    "       tune_tree(tree.right, X, y)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36787ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_all_decisions(tf, X, y):\n",
    "    #infile = open(args.structure, 'r')\n",
    "    tree = make_tree(tf)\n",
    "    tune_tree(tree, X, y)\n",
    "    #tree.to_json(args.output)\n",
    "    return(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "treefile = \"src/raw_tree.json\"\n",
    "tree = tune_all_decisions(treefile, log_train, train_labels)\n",
    "tree.fit(log_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tree.predict(log_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as CR\n",
    "print(CR(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/bg_sub')\n",
    "ecurves = np.zeros((len(files),train_curves.shape[1]))\n",
    "for (i,file) in enumerate(files):\n",
    "    indf = pd.DataFrame(pd.read_csv(\"data/bg_sub/%s\"%(file), sep='\\s+'))\n",
    "    ecurves[i,:] = np.array(indf.loc[:,\"I\"])\n",
    "ecurves = bg_norm(ecurves)\n",
    "log_exp = np.log10(ecurves)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1363250",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpreds = tree.predict(log_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(indf.loc[:,'q'], train_curves[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30513f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ecurves.shape[0]):\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.scatter(indf.loc[:,'q'], ecurves[i,:])\n",
    "    plt.title(\"%s %s\"%(files[i].replace(\".csv\",\"\"), rpreds[i]))\n",
    "    plt.xlabel(r'Q, ($\\AA^{-1}$')\n",
    "    plt.ylabel(r'I(Q) (cm$^{-1}$)')\n",
    "    plt.savefig(\"resplots/%s\"%(files[i].replace(\".csv\", \".png\")))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc9cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd98cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounds(params, labels, target):\n",
    "    target_ranges = {}\n",
    "    valid = np.where(labels==target)[0]\n",
    "    for (key, values) in params.items():\n",
    "        vals = values[valid]\n",
    "        if key in numeric_params and all(np.isfinite(vals)):\n",
    "          #  try:\n",
    "               vmin = np.min(vals)\n",
    "               vmax = np.max(vals)\n",
    "               if np.isfinite(vmin) and np.isfinite(vmax):\n",
    "                   target_ranges[key] = {\"min\": vmin, \"max\": vmax}\n",
    "         #   except:\n",
    "         #      print('excepting %s %s'%(target, key))\n",
    "        else:\n",
    "            if vals[0] is not None:\n",
    "                vmin = vals[0]\n",
    "                vmax = vals[0]\n",
    "                if vmin is not np.nan:\n",
    "                     target_ranges[key] = {\"min\": vmin, \"max\": vmax}\n",
    "    return(target_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0505d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3167a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccec9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edf7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d79e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13376670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {target:find_bounds(train_params, train_labels, target) for target in np.unique(train_labels)}\n",
    "for t in np.unique(train_labels):\n",
    "    print(t)\n",
    "    outfile = open('%s_range.csv'%(t), 'w')\n",
    "    for (key,vals) in ranges[t].items():\n",
    "        outfile.write(\"%s,%s,%s\\n\"%(key, str(vals['min']), str(vals['max'])))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ranges['flexible_cylinder_elliptical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3392fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c60d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(train_params['radius'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.unique(train_labels):\n",
    "    valid = np.where(train_labels == t)[0]\n",
    "    print(\"%s %f\"%(t, np.mean(log_train[valid,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb507eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(train_params['scale'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37e868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, curve) in enumerate(log_exp):\n",
    "    print(\"%d %s %f %s\"%(i, files[i], curve[0], rpreds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88379e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_scale(index, title = None):\n",
    "    scales_to_test = np.linspace(0.005, 0.2, 100)\n",
    "    mn = train_labels[index]\n",
    "    if mn in model_names.keys():\n",
    "        model_name = model_names[mn]\n",
    "    else:\n",
    "        model_name = mn\n",
    "    tcurves = []\n",
    "    tdict = {p:i[index] for (p,i) in train_params.items() if should_include_param(i[index])}\n",
    "    print(tdict)\n",
    "    calcs, sds = vi.construct_calculators(model_name)\n",
    "    for s in scales_to_test:\n",
    "        tdict['scale'] = s\n",
    "        tcurves += [np.array(vi.generate(model_name, tdict, calcs, sds)[0])]\n",
    "    intensities = [np.log10(c)[0] for c in tcurves]\n",
    "    plt.scatter(scales_to_test, intensities)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdaba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_include_param(val):\n",
    "    return_value = True\n",
    "    if val is None:\n",
    "        return_value = False\n",
    "    elif type(val) == np.float64:\n",
    "        if not np.isfinite(val):\n",
    "            return_value = False\n",
    "    elif type(val) == np.int64:\n",
    "        if not np.isfinite(val) or val < 0:\n",
    "            return_value = False\n",
    "    return(return_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'flexible_cylinder_elliptical'\n",
    "for target in np.unique(train_labels):\n",
    "    compare_scale(np.random.choice(np.where(train_labels == target)[0]), title = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d63bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e774c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rind = np.random.choice(np.arange(train_labels.shape[0]))\n",
    "indf = pd.DataFrame(pd.read_csv(reference_files[0], sep = '\\s+'))\n",
    "print(indf.columns)\n",
    "q = indf.loc[:,'q']\n",
    "print(q)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(q, train_curves[rind, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a553cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f1ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,le) in enumerate(log_exp):\n",
    "    print(\"%f %s\"%(le[0], rpreds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b49a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025629f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(train_curves, train_labels, target):\n",
    "    valid = np.where(train_labels==target)[0]\n",
    "    np.random.shuffle(valid)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.title(target)\n",
    "    for i in valid[:5]:\n",
    "       plt.scatter(q, train_curves[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.unique(train_labels):\n",
    "    plot_sample(train_curves, train_labels, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TreeEncoder\n",
    "encodefile = open(\"trained_tree_temp.json\", 'w')\n",
    "encodefile.write(json.dumps(tree, cls=TreeEncoder.TreeEncoder, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f085730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((2 * np.pi)/0.3)\n",
    "print((2*np.pi)/np.min(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9954a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.002*np.ones(train_curves.shape)+(np.random.normal(size = train_curves.shape)*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e07e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "indf.loc[140:dI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c021e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
